{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yRuQQKUeSHcH"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BIOINFORMATICS: LAB08\n",
    "@author: Irene Benedetto\n",
    "\"\"\"\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import warnings\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uqYEsxySHYS",
    "outputId": "61bd7194-f3d0-4042-9a93-04bbadeb0888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the transcriptome dataframe: (500, 131)\n",
      "Length of the genome dataframe: (500, 367)\n",
      "Length of the proteome dataframe: (500, 160)\n"
     ]
    }
   ],
   "source": [
    "transcriptome_df, genome_df, proteome_df, labels_df = create_dataframe()\n",
    "\n",
    "transcriptome_df = transcriptome_df.astype(np.float32)\n",
    "genome_df = genome_df.astype(np.float32)\n",
    "proteome_df = proteome_df.astype(np.float32)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "labels_df.groupby(['cluster.id']).size().plot(kind='bar', title='Class distribution in the dataset')\n",
    "plt.savefig('class_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbxGuG5LTQDA"
   },
   "source": [
    "# Early integration approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_382-8dTTLN"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_mK6A09S2E-",
    "outputId": "5025616c-eba1-4c52-b2ab-c903fcc4fbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the complete dataframe: (500, 658)\n",
      "Length of the labels: (500,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([transcriptome_df, genome_df, proteome_df], axis=1)\n",
    "\n",
    "print(f'Length of the complete dataframe: {df.shape}')\n",
    "print(f'Length of the labels: {labels_df[\"cluster.id\"].shape}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, labels_df[\"cluster.id\"].values, stratify=labels_df[\"cluster.id\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9L6a2MLTXOX"
   },
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "ihItgIJHSVkl",
    "outputId": "8e4d5449-2e27-4785-e194-b32f9c0cdfd9"
   },
   "outputs": [],
   "source": [
    "explained_vars = {}\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "MAX_FTS = 375\n",
    "for i in range(1, MAX_FTS):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(X_train)\n",
    "    explained_vars[i] = pca.explained_variance_ratio_[-1]\n",
    "\n",
    "plt.plot(list(explained_vars.keys()), list(explained_vars.values()))\n",
    "plt.plot(list(explained_vars.keys()), np.cumsum(list(explained_vars.values())))\n",
    "plt.xlabel('Principal component')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.title('Proportion of explained variance (ratio and cumulative) over the components')\n",
    "plt.grid()\n",
    "plt.savefig('explained_variance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kOvjWNtoSVg-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of variance explained with 50: 0.8753693103790283\n"
     ]
    }
   ],
   "source": [
    "# the number of features is setted to 20\n",
    "N_FTS = 50\n",
    "selector = PCA(n_components=N_FTS)\n",
    "selector.fit(X_train)\n",
    "reduced_X_train = selector.transform(X_train)\n",
    "reduced_X_test = selector.transform(X_test)\n",
    "print(f'Proportion of variance explained with {N_FTS}: {np.sum(selector.explained_variance_ratio_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2RPoJzlTgNH"
   },
   "source": [
    "## Algorithms and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VeJAYXY2ThsW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "Best configuration: {'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "Accuracy on validation set (5 folds): 1.0\n",
      "\n",
      "KNeighborsClassifier\n",
      "Best configuration: {'n_neighbors': 1}\n",
      "Accuracy on validation set (5 folds): 1.0\n",
      "\n",
      "RandomForestClassifier\n",
      "Best configuration: {'criterion': 'gini', 'n_estimators': 20, 'oob_score': True}\n",
      "Accuracy on validation set (5 folds): 1.0\n",
      "\n",
      "LogisticRegression\n",
      "Best configuration: {'C': 0.001}\n",
      "Accuracy on validation set (5 folds): 1.0\n",
      "\n",
      "Best classifier: MLPClassifier\n",
      "Accuracy on the test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# search for the best classifier and its best configuration of hyperparameters\n",
    "_ = hyperparameter_tuning(reduced_X_train, y_train, reduced_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late integration approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GwBUOXmySe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LATE INTEGRATION APPROACH\n",
      "\n",
      "Transcriptome dataset\n",
      "Best classifier: MLPClassifier\n",
      "Accuracy on the test set: 1.0\n",
      "\n",
      "Genome dataset\n",
      "Best classifier: MLPClassifier\n",
      "Accuracy on the test set: 1.0\n",
      "\n",
      "Proteome dataset\n",
      "Best classifier: MLPClassifier\n",
      "Accuracy on the test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# LATE INTEGRATION APPROACH\n",
    "print('\\n\\nLATE INTEGRATION APPROACH')\n",
    "\n",
    "# for each dataset transcriptome_df, genome_df, proteome_df we need to find the optimal\n",
    "\n",
    "# for the transcriptome dataframe\n",
    "print('\\nTranscriptome dataset')\n",
    "X_train, X_test, y_train, y_test = train_test_split(transcriptome_df, labels_df[\"cluster.id\"].values, shuffle=False)\n",
    "# implementing 4 different classifiers\n",
    "best_clf = hyperparameter_tuning(X_train, y_train, X_test, y_test, verbose=False)\n",
    "transcriptome_probabilities = best_clf.predict_proba(X_test)\n",
    "transcriptome_probabilities = np.array(transcriptome_probabilities)\n",
    "\n",
    "# for the genome dataframe\n",
    "print('\\nGenome dataset')\n",
    "X_train, X_test, y_train, y_test = train_test_split(genome_df, labels_df[\"cluster.id\"].values, shuffle=False)\n",
    "# implementing 4 different classifiers\n",
    "best_clf = hyperparameter_tuning(X_train, y_train, X_test, y_test, verbose=False)\n",
    "genome_probabilities = best_clf.predict_proba(X_test)\n",
    "genome_probabilities = np.array(genome_probabilities)\n",
    "\n",
    "# for the proteome dataframe\n",
    "print('\\nProteome dataset')\n",
    "X_train, X_test, y_train, y_test = train_test_split(proteome_df, labels_df[\"cluster.id\"].values, shuffle=False)\n",
    "# implementing 4 different classifiers\n",
    "best_clf = hyperparameter_tuning(X_train, y_train, X_test, y_test, verbose=False)\n",
    "proteome_probabilities = best_clf.predict_proba(X_test)\n",
    "proteome_probabilities = np.array(proteome_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late integration consensus building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aYoOqsLxSl1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unknown: 3\n",
      "Class 1, accuracy: 0.93\n",
      "Class 2, accuracy: 1.0\n",
      "Class 3, accuracy: 1.0\n",
      "Class 4, accuracy: 0.97\n",
      "Class 5, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = 0.99\n",
    "y_pred = []\n",
    "for sample in range(transcriptome_probabilities.shape[0]):\n",
    "    # for each sample extract the probabilities according to:\n",
    "    # - each features (on the colums)\n",
    "    #  - each class (on the row)\n",
    "    probabilities = [\n",
    "        transcriptome_probabilities[sample],\n",
    "        genome_probabilities[sample],\n",
    "        proteome_probabilities[sample]\n",
    "    ]\n",
    "\n",
    "    probabilities = np.array(probabilities).T\n",
    "\n",
    "    S_a = np.sum(probabilities)\n",
    "    S_i = np.sum(probabilities, axis=1)\n",
    "    m = 3\n",
    "    S_m = S_i / m\n",
    "\n",
    "    if (np.max(S_i) / S_a < threshold) or (np.max(S_m) < threshold):\n",
    "        y = 'Unknown'\n",
    "    else:\n",
    "        y = str(np.argmax(S_i) + 1)\n",
    "    y_pred.append(y)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "n_unknown = len(np.where(y_pred == 'Unknown')[0])\n",
    "print(f'\\nNumber of unknown: {n_unknown}')\n",
    "\n",
    "for c in range(1, 6):\n",
    "    correct = len(np.where((y_pred == f'{c}') * (y_test == c))[0])\n",
    "    n = len(np.where(y_test == c)[0])\n",
    "    print(f'Class {str(c)}, accuracy: {round(correct / n, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
